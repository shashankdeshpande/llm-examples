{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJxXjWdfHJB3kTGDA5XBVd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashankdeshpande/llm-examples/blob/master/OpenAI-API-Function-Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TOC:\n",
        "* [OpenAI - Function calling capability](#chapter1)\n",
        "* [Multiple / Sequential Function Calling - OpenAI API](#chapter2)"
      ],
      "metadata": {
        "id": "VtM-VeXIVLyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name=\"chapter1\"></a>OpenAI - Function calling capability\n",
        "\n",
        "OpenAI has recently introduced a new capability called function calling, which allows developers to retrieve structured outputs from the GPT-4 and GPT-3.5 models.\n",
        "\n",
        "This feature enables chatbots to leverage external tools, transform natural language into database queries, and extract structured data from text. The models have been fine-tuned to identify instances where a function should be invoked and provide JSON responses that align with the function arguments. Function calling allows developers to more reliably get structured data back from the model\n",
        "\n",
        "**Reference** - https://openai.com/blog/function-calling-and-other-api-updates"
      ],
      "metadata": {
        "id": "V0tealCpm_8F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9sBwtTym7Nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc0e293-ef23-4f59-eaac-4749e50b10b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q openai dateparser"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import openai\n",
        "import logging\n",
        "import requests\n",
        "import traceback\n",
        "import dateparser"
      ],
      "metadata": {
        "id": "ZP7QSWpn0cIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger('OpenAI-Example')\n",
        "logger.setLevel(logging.INFO)"
      ],
      "metadata": {
        "id": "Qsd_7ycmtGAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your key here - https://platform.openai.com/account/api-keys\n",
        "\n",
        "openai.api_key = \"YOUR_OPENAI_KEY_HERE\""
      ],
      "metadata": {
        "id": "JRA83lca_bmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1 - Create a custom function\n",
        "In this step, we will be creating a personalized function that will retrieve country-specific trends upon request.\n",
        "\n",
        "We are referring google trends from here - https://trends.google.com/trends/trendingsearches/daily?geo=IN&hl=en-GB"
      ],
      "metadata": {
        "id": "gu_b33L8lJQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_google_trends(country_code, date_string='today'):\n",
        "    \"\"\"Method to retrieve country specific trends\n",
        "\n",
        "    Args:\n",
        "        country_code (str): alpha-2 country code, example - IN,US,UK\n",
        "        date_string (str): date string supported by dateparser, example - today, yesterday\n",
        "\n",
        "    Returns:\n",
        "        list: list of dict having trend query and traffic details\n",
        "    \"\"\"\n",
        "    trends = []\n",
        "    try:\n",
        "        logger.info(f'received args - country_code: {country_code}, date_string: {date_string}')\n",
        "        dt = dateparser.parse(date_string).strftime('%Y%m%d')\n",
        "        url = 'https://trends.google.com/trends/api/dailytrends'\n",
        "        params = {'hl':'en-GB','tz':-330, 'geo': country_code, 'ns':15, 'ed': dt}\n",
        "        response = requests.get(url, params=params, timeout=5)\n",
        "        if response.status_code == 200:\n",
        "            tinfo = json.loads(response.content[5:])\n",
        "            tinfo = tinfo['default']['trendingSearchesDays'][0]\n",
        "            if tinfo['date'] == dt:\n",
        "                for i in tinfo['trendingSearches']:\n",
        "                    trends.append({\n",
        "                        'query': i['title']['query'],\n",
        "                        'traffic': i['formattedTraffic']\n",
        "                    })\n",
        "    except Exception as e:\n",
        "        logger.error('Error in get_trends: \\n {}'.format(traceback.format_exc()))\n",
        "    return trends"
      ],
      "metadata": {
        "id": "qjYqgyl024FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_google_trends('IN')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCIDfc8el-gx",
        "outputId": "0c8c3fb9-d3ae-4c7f-daad-c53bc41eac3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:received args - country_code: IN, date_string: today\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'query': 'Messi', 'traffic': '100K+'},\n",
              " {'query': 'Wagner Group', 'traffic': '20K+'},\n",
              " {'query': 'Lionel Messi', 'traffic': '20K+'},\n",
              " {'query': 'Rahul Gandhi', 'traffic': '20K+'},\n",
              " {'query': 'Ruturaj Gaikwad', 'traffic': '10K+'},\n",
              " {'query': 'TSPSC Group 4 Hall Ticket', 'traffic': '10K+'},\n",
              " {'query': 'Mary Millben', 'traffic': '10K+'},\n",
              " {'query': 'Lionel Messi Birthday', 'traffic': '5K+'}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 - Specify necessary function details as required by OpenAI\n",
        "Make sure to mention clear and detailed description for function as well as arguments required by that function. This will assist the OpenAI model in determining the appropriate usage of the function and aid in extracting the essential entities from user queries.\n",
        "\n",
        "We can have details of multiple functions, currently experimenting with only one."
      ],
      "metadata": {
        "id": "GU-ksUeFm6kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_function_info = [\n",
        "    {\n",
        "        \"name\": \"get_google_trends\",\n",
        "        \"description\": \"Get list of trending queries along with traffic observed\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"country_code\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"alpha-2 country code\",\n",
        "                },\n",
        "                \"date_string\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"date string supported by dateparser\"\n",
        "                    },\n",
        "            },\n",
        "            \"required\": [\"country_code\", \"date_string\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "PWCaCVLwCA3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 - Call OpenAI API with custom function details"
      ],
      "metadata": {
        "id": "2oBurMVPoerR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Show me current google trends in India\"\n",
        "\n",
        "openai_model = \"gpt-3.5-turbo-0613\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model=openai_model,\n",
        "    messages=[{\"role\": \"user\", \"content\": user_query}],\n",
        "    functions=custom_function_info,\n",
        "    function_call=\"auto\", #OpenAI will determine whether a custom function is necessary or not based on query, otherwise can set this as {\"name\": \"get_google_trends\"}\n",
        ")"
      ],
      "metadata": {
        "id": "RbnVpfJ87a3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4wudg8Q_Ufu",
        "outputId": "f6b51b9d-5174-4319-8e3e-4e2736fdbc4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7Utl9iv3YiXanW1Rd6dYl07TQBoKz at 0x7fb650c837e0> JSON: {\n",
              "  \"id\": \"chatcmpl-7Utl9iv3YiXanW1Rd6dYl07TQBoKz\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1687598535,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": null,\n",
              "        \"function_call\": {\n",
              "          \"name\": \"get_google_trends\",\n",
              "          \"arguments\": \"{\\n  \\\"country_code\\\": \\\"IN\\\",\\n  \\\"date_string\\\": \\\"today\\\"\\n}\"\n",
              "        }\n",
              "      },\n",
              "      \"finish_reason\": \"function_call\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 79,\n",
              "    \"completion_tokens\": 26,\n",
              "    \"total_tokens\": 105\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4 - Retrieve identified arguments from the response and call the custom function"
      ],
      "metadata": {
        "id": "0o9RMDpXpJN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "identified_func = response.choices[0].message.to_dict()\n",
        "print('Response function call: ', identified_func)\n",
        "\n",
        "identified_func_args = identified_func['function_call']['arguments']\n",
        "identified_func_args = json.loads(identified_func_args)\n",
        "print('Function arguments: ', identified_func_args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "au_VgSh1_0Nt",
        "outputId": "ec64f18c-418d-47f6-fc76-105ca04ad6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response function call:  {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7fb650d9fec0> JSON: {\n",
            "  \"name\": \"get_google_trends\",\n",
            "  \"arguments\": \"{\\n  \\\"country_code\\\": \\\"IN\\\",\\n  \\\"date_string\\\": \\\"today\\\"\\n}\"\n",
            "}}\n",
            "Function arguments:  {'country_code': 'IN', 'date_string': 'today'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func_output = get_google_trends(**identified_func_args)\n",
        "func_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwbfTxtmppo9",
        "outputId": "25b03602-e45d-480a-c43b-0de5e57bafa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:received args - country_code: IN, date_string: today\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'query': 'Messi', 'traffic': '100K+'},\n",
              " {'query': 'Wagner Group', 'traffic': '20K+'},\n",
              " {'query': 'Lionel Messi', 'traffic': '20K+'},\n",
              " {'query': 'Rahul Gandhi', 'traffic': '20K+'},\n",
              " {'query': 'Ruturaj Gaikwad', 'traffic': '10K+'},\n",
              " {'query': 'TSPSC Group 4 Hall Ticket', 'traffic': '10K+'},\n",
              " {'query': 'Mary Millben', 'traffic': '10K+'},\n",
              " {'query': 'Lionel Messi Birthday', 'traffic': '5K+'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Call OpenAI with function output and query to get answer"
      ],
      "metadata": {
        "id": "Io1LJC4_p_YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_response = openai.ChatCompletion.create(\n",
        "    model=openai_model,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": user_query},\n",
        "        {\"role\": \"assistant\", \"content\": None, \"function_call\": {\"name\": \"get_current_weather\", \"arguments\": json.dumps(identified_func_args)}},\n",
        "        {\"role\": \"function\", \"name\": \"get_google_trends\", \"content\": json.dumps(func_output)}\n",
        "        ],\n",
        "    functions=custom_function_info\n",
        ")"
      ],
      "metadata": {
        "id": "ohWci9ONAiT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUW2NxGQqsED",
        "outputId": "6f54671a-88db-454c-b840-642183351833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject chat.completion id=chatcmpl-7UtlQ3BqPFyZ7XNeYczOPfpSGBR6M at 0x7fb651dcb470> JSON: {\n",
              "  \"id\": \"chatcmpl-7UtlQ3BqPFyZ7XNeYczOPfpSGBR6M\",\n",
              "  \"object\": \"chat.completion\",\n",
              "  \"created\": 1687598552,\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"choices\": [\n",
              "    {\n",
              "      \"index\": 0,\n",
              "      \"message\": {\n",
              "        \"role\": \"assistant\",\n",
              "        \"content\": \"Here are the current Google trends in India:\\n\\n1. Messi - 100K+\\n2. Wagner Group - 20K+\\n3. Lionel Messi - 20K+\\n4. Rahul Gandhi - 20K+\\n5. Ruturaj Gaikwad - 10K+\\n6. TSPSC Group 4 Hall Ticket - 10K+\\n7. Mary Millben - 10K+\\n8. Lionel Messi Birthday - 5K+\"\n",
              "      },\n",
              "      \"finish_reason\": \"stop\"\n",
              "    }\n",
              "  ],\n",
              "  \"usage\": {\n",
              "    \"prompt_tokens\": 252,\n",
              "    \"completion_tokens\": 94,\n",
              "    \"total_tokens\": 346\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_response.choices[0]['message']['content'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZcSIqGtAmgE",
        "outputId": "f33ac7c4-ac3f-404e-a627-ad298b45d18b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the current Google trends in India:\n",
            "\n",
            "1. Messi - 100K+\n",
            "2. Wagner Group - 20K+\n",
            "3. Lionel Messi - 20K+\n",
            "4. Rahul Gandhi - 20K+\n",
            "5. Ruturaj Gaikwad - 10K+\n",
            "6. TSPSC Group 4 Hall Ticket - 10K+\n",
            "7. Mary Millben - 10K+\n",
            "8. Lionel Messi Birthday - 5K+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consolidating all these elements ..\n",
        "Creating a separate function which will return respond to user query"
      ],
      "metadata": {
        "id": "sWsbqXYUsqYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_openai(user_query):\n",
        "    answer = ''\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=openai_model,\n",
        "        messages=[{\"role\": \"user\", \"content\": user_query}],\n",
        "        functions=custom_function_info,\n",
        "        function_call=\"auto\"\n",
        "    )\n",
        "    resp = response.choices[0].message.to_dict()\n",
        "    if 'function_call' in resp:\n",
        "        identified_func_args = json.loads(resp['function_call']['arguments'])\n",
        "        func_output = get_google_trends(**identified_func_args)\n",
        "        final_response = openai.ChatCompletion.create(\n",
        "            model=openai_model,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": user_query},\n",
        "                {\"role\": \"assistant\", \"content\": None, \"function_call\": {\"name\": resp['function_call']['name'], \"arguments\": json.dumps(identified_func_args)}},\n",
        "                {\"role\": \"function\", \"name\": resp['function_call']['name'], \"content\": json.dumps(func_output)}\n",
        "                ],\n",
        "            functions=custom_function_info\n",
        "        )\n",
        "        answer = final_response.choices[0]['message']['content']\n",
        "    else:\n",
        "        answer = resp['content']\n",
        "    return answer"
      ],
      "metadata": {
        "id": "or3lnl--ssn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example, OpenAI correctly identifies country which user was referring to, and also provide additional information by utilizing function output\n",
        "\n",
        "answer = ask_openai('Which is the most popular search trend in the nation with the largest democracy. Tell me more about that')\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iVD4BDrtQpF",
        "outputId": "8c10654c-c5ef-4a03-fb13-be62154348ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:received args - country_code: IN, date_string: today\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most popular search trend in India, which is the nation with the largest democracy, is \"Messi\". This search term has a traffic volume of over 100K+ searches today. \n",
            "\n",
            "\"Messi\" refers to Lionel Messi, the Argentine professional football player, who is considered one of the greatest footballers of all time. He has a massive fan following around the world, including in India. People may be searching for updates on his latest matches, goals, news, or other information related to his career.\n",
            "\n",
            "It's worth noting that other popular search trends in India today include \"Wagner Group\" and \"Rahul Gandhi,\" each with a traffic volume of 20K+ searches. Wagner Group is a private military company, and Rahul Gandhi is an Indian politician and the former president of the Indian National Congress party.\n",
            "\n",
            "Overall, \"Messi\" is currently the most popular search trend in India, reflecting the immense popularity and interest in football in the country.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = ask_openai('Could you provide information on the topic that was trending in the US yesterday and share the traffic data for the most popular trend?')\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7EwvkkQuehf",
        "outputId": "f6361211-c1a5-410a-8310-8fa4f568f26d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:received args - country_code: US, date_string: yesterday\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following topics were trending in the US yesterday:\n",
            "\n",
            "1. Russia - 500K+ traffic\n",
            "2. Kim Petras - 100K+ traffic\n",
            "3. Frozen fruit recall - 50K+ traffic\n",
            "4. Reds - 50K+ traffic\n",
            "5. Cincinnati Reds - 50K+ traffic\n",
            "6. Evil Dead Rise - 50K+ traffic\n",
            "7. Jordan Walsh - 50K+ traffic\n",
            "8. Damian Lillard - 20K+ traffic\n",
            "9. Lonzo Ball - 20K+ traffic\n",
            "10. Taylor Swift Minneapolis - 20K+ traffic\n",
            "11. Highlands Ranch tornado - 20K+ traffic\n",
            "12. Marcus Sasser - 20K+ traffic\n",
            "13. Lab-grown meat - 20K+ traffic\n",
            "14. Knicks - 20K+ traffic\n",
            "15. Adam Rich - 20K+ traffic\n",
            "16. Nick Smith Jr - 20K+ traffic\n",
            "\n",
            "The most popular trend based on traffic was \"Russia\" with over 500K searches.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In this example, custom function is not utilized which is correct\n",
        "\n",
        "answer = ask_openai('Can you explain blockchain in simple terms')\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8GW06T-tRQN",
        "outputId": "3ff66874-d881-4391-f46b-8555041cab25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Certainly! Blockchain is a technology that allows multiple parties to maintain a secure and transparent record of transactions or information without the need for a central authority, such as a bank or government.\n",
            "\n",
            "Imagine a digital ledger or spreadsheet that is shared and continuously updated across a network of computers called nodes. Each node has a copy of this ledger and verifies the transactions or information recorded on it.\n",
            "\n",
            "When a new transaction or piece of information needs to be added to the ledger, it is grouped together with other transactions into a block. Before this block is added to the chain, it goes through a process called \"consensus.\" This means that the nodes in the network agree that the information in the block is valid and should be added.\n",
            "\n",
            "Once a block is approved and added to the chain, it becomes a permanent part of the ledger and cannot be altered or deleted. Each block also contains a reference to the previous block, creating a chain of linked blocks.\n",
            "\n",
            "This system of decentralized consensus and immutability makes blockchain highly secure and tamper-resistant. It ensures that records remain transparent and trustworthy, as anyone can view the entire history of transactions or information stored on the blockchain.\n",
            "\n",
            "Blockchain technology has various applications, with the most well-known being cryptocurrencies like Bitcoin. However, it can also be used in areas such as supply chain management, voting systems, smart contracts, and more.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <a name=\"chapter2\"></a>Multiple / Sequential Function Calling - OpenAI API\n",
        "\n",
        "Exploring capabilities of `function_call` usage for recurrent/sequential functions -\n",
        "\n",
        "For the purpose of understanding, we will utilize the contents of the `sample_folder` and experiment with the folder's contents."
      ],
      "metadata": {
        "id": "gM_CI37W0sVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q humanfriendly"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt5s3AQ7SxMR",
        "outputId": "f78d87c5-6d93-4e93-c3d6-de18cdc8f639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import traceback\n",
        "import humanfriendly\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_folder_contents(path):\n",
        "    contents = []\n",
        "    try:\n",
        "        for file in os.listdir(path):\n",
        "            size_bytes = os.stat(os.path.join(path, file)).st_size\n",
        "            size = humanfriendly.format_size(size_bytes)\n",
        "            contents.append({\n",
        "                'file_name': file,\n",
        "                'size': size\n",
        "            })\n",
        "    except Exception as e:\n",
        "        logger.error('Error in get_folder_contents:\\n {}'.format(traceback.format_exc()))\n",
        "    return contents\n",
        "\n",
        "def create_folder(name):\n",
        "    if not os.path.exists(name):\n",
        "        os.makedirs(name)\n",
        "        msg = f'Folder creation succesfull: {name}'\n",
        "    else:\n",
        "        msg = f'Folder already exists: {name}'\n",
        "    return msg\n",
        "\n",
        "def copy_file(src, dest):\n",
        "    if not os.path.exists(dest):\n",
        "        os.makedirs(dest)\n",
        "    shutil.copy(src, dest)\n",
        "    return f'Copy successfull: {src} to {dest}'"
      ],
      "metadata": {
        "id": "jck4bSkb0w-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_folder_contents('/content/sample_data/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giGc6mYvRS3r",
        "outputId": "ee26e7d1-6a7d-4669-d24c-e9ed1ae32a7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'file_name': 'anscombe.json', 'size': '1.7 KB'},\n",
              " {'file_name': 'README.md', 'size': '930 bytes'},\n",
              " {'file_name': 'mnist_test.csv', 'size': '18.29 MB'},\n",
              " {'file_name': 'mnist_train_small.csv', 'size': '36.52 MB'},\n",
              " {'file_name': 'california_housing_train.csv', 'size': '1.71 MB'},\n",
              " {'file_name': 'california_housing_test.csv', 'size': '301.14 KB'}]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func_name_map = {\n",
        "    'get_folder_contents': get_folder_contents,\n",
        "    'create_folder': create_folder,\n",
        "    'copy_file': copy_file\n",
        "    }"
      ],
      "metadata": {
        "id": "gzDxN80O1XiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_function_info = [\n",
        "    {\n",
        "        \"name\": \"get_folder_contents\",\n",
        "        \"description\": \"Use this function to obtain a list of files present in a specified folder, including their respective sizes in human readable format\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"path\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": f\"Full path of the folder, should start with {os.getcwd()}\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"path\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"create_folder\",\n",
        "        \"description\": \"Use this function to create new folder\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"name of new folder, don't forget to replace all spaces with underscores\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"name\"],\n",
        "        },\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"copy_file\",\n",
        "        \"description\": \"Use this function to copy file to specified destination\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"src\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"full source path of the file which is to be copied\",\n",
        "                },\n",
        "                \"dest\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"full path of the destination folder. Make sure not include file name as folder\",\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"src\",\"dest\"],\n",
        "        },\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "hJtsCeO8hMyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ask_openai(user_query, openai_model=\"gpt-3.5-turbo-0613\"):\n",
        "    answer = ''\n",
        "    messages = [\n",
        "        {\"role\": \"system\",\"content\": \"\"\"\n",
        "                You are intelligent chatbot.\n",
        "                You are only allowed to use specified functions with relevant order by looking at the user query and context.\n",
        "                You don’t have a python function available, never attempt to call python\n",
        "                \"\"\"},\n",
        "        {\"role\": \"user\", \"content\": user_query}\n",
        "        ]\n",
        "    while True:\n",
        "        logger.info(f'Calling API: {messages}')\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=openai_model,\n",
        "            messages=messages,\n",
        "            functions=custom_function_info,\n",
        "            function_call='auto'\n",
        "        )\n",
        "        resp = response.choices[0].message.to_dict()\n",
        "        logger.info(f'API Response: {resp}')\n",
        "        if 'function_call' in resp:\n",
        "            func_call_resp = resp['function_call']\n",
        "            identified_func = func_call_resp['name']\n",
        "            identified_func_args = json.loads(func_call_resp['arguments'])\n",
        "            func_output = func_name_map[identified_func](**identified_func_args)\n",
        "            messages.extend([\n",
        "                {\"role\": \"assistant\", \"content\": None, \"function_call\": {\"name\": identified_func, \"arguments\": json.dumps(identified_func_args)}},\n",
        "                {\"role\": \"function\", \"name\": identified_func, \"content\": json.dumps(func_output)},\n",
        "\n",
        "                {\"role\": \"user\", 'content': f\"User query was - {user_query}. The previous function returned {json.dumps(func_output)}. Suggest next steps if any as per user query and context, else respond with relevant answer\"}\n",
        "            ])\n",
        "        else:\n",
        "            break\n",
        "\n",
        "        # added this to avoid RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues.\n",
        "        sleep_seconds = 30\n",
        "        for i in tqdm(range(sleep_seconds), desc='Sleeping'):\n",
        "            time.sleep(1)\n",
        "\n",
        "    answer = resp['content']\n",
        "    return answer"
      ],
      "metadata": {
        "id": "rr-AwUMv1jat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# original folder structure\n",
        "\n",
        "!ls -lR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqMZ_-QQpvSB",
        "outputId": "258b598c-06c4-4f71-d0c0-696f7455ec1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "total 4\n",
            "drwxr-xr-x 1 root root 4096 Jun 23 01:15 sample_data\n",
            "\n",
            "./sample_data:\n",
            "total 55504\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root   301141 Jun 23 01:15 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Jun 23 01:15 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root 18289443 Jun 23 01:15 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jun 23 01:15 mnist_train_small.csv\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 1: Single function usage"
      ],
      "metadata": {
        "id": "pWBl2hdACdF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Which file is the largest in the sample_data folder? \"\n",
        "answer = ask_openai(user_query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td1D4pGXmJPc",
        "outputId": "52cff9a2-4158-4b0e-af0e-42b2d3cddfbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Which file is the largest in the sample_data folder? '}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb41214e0> JSON: {\n",
            "  \"name\": \"get_folder_contents\",\n",
            "  \"arguments\": \"{\\n\\\"path\\\": \\\"/content/sample_data\\\"\\n}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Which file is the largest in the sample_data folder? '}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_folder_contents', 'arguments': '{\"path\": \"/content/sample_data\"}'}}, {'role': 'function', 'name': 'get_folder_contents', 'content': '[{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]'}, {'role': 'user', 'content': 'User query was - Which file is the largest in the sample_data folder? . The previous function returned [{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]. Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': 'The largest file in the sample_data folder is \"mnist_train_small.csv\" with a size of 36.52 MB.'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The largest file in the sample_data folder is \"mnist_train_small.csv\" with a size of 36.52 MB.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 2: Single function recurrent usage"
      ],
      "metadata": {
        "id": "eKHzU4R8CoQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Create two new folder namely new_folder1 and new_folder2\"\n",
        "answer = ask_openai(user_query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIqWZaT-p5Ki",
        "outputId": "eef7b6ed-622f-4da1-a580-e1e12e02d4d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely new_folder1 and new_folder2'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb4176cf0> JSON: {\n",
            "  \"name\": \"create_folder\",\n",
            "  \"arguments\": \"{\\\"name\\\": \\\"new_folder1\\\"}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely new_folder1 and new_folder2'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"new_folder1\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: new_folder1\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely new_folder1 and new_folder2. The previous function returned \"Folder creation succesfull: new_folder1\". Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb40d0ae0> JSON: {\n",
            "  \"name\": \"create_folder\",\n",
            "  \"arguments\": \"{\\\"name\\\": \\\"new_folder2\\\"}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely new_folder1 and new_folder2'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"new_folder1\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: new_folder1\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely new_folder1 and new_folder2. The previous function returned \"Folder creation succesfull: new_folder1\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"new_folder2\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: new_folder2\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely new_folder1 and new_folder2. The previous function returned \"Folder creation succesfull: new_folder2\". Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': 'You have successfully created the two new folders - new_folder1 and new_folder2. Is there anything else I can assist you with?'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have successfully created the two new folders - new_folder1 and new_folder2. Is there anything else I can assist you with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modified folder structure\n",
        "\n",
        "!ls -lR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzuqCWRBCwBS",
        "outputId": "2e42cbd0-b55f-40c8-9c14-6fe8834de5cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Jun 26 14:10 new_folder1\n",
            "drwxr-xr-x 2 root root 4096 Jun 26 14:11 new_folder2\n",
            "drwxr-xr-x 1 root root 4096 Jun 23 01:15 sample_data\n",
            "\n",
            "./new_folder1:\n",
            "total 0\n",
            "\n",
            "./new_folder2:\n",
            "total 0\n",
            "\n",
            "./sample_data:\n",
            "total 55504\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root   301141 Jun 23 01:15 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Jun 23 01:15 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root 18289443 Jun 23 01:15 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jun 23 01:15 mnist_train_small.csv\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example 3: Complex query - invloves multiple and recurrent function usage"
      ],
      "metadata": {
        "id": "Z1K0nWGAC6G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file\"\n",
        "answer = ask_openai(user_query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynQAKAr9ob6t",
        "outputId": "3f07e5a9-a16d-4df3-930d-1cb09b495e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb42a6520> JSON: {\n",
            "  \"name\": \"create_folder\",\n",
            "  \"arguments\": \"{\\n  \\\"name\\\": \\\"big-file\\\"\\n}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"big-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: big-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: big-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb4121bc0> JSON: {\n",
            "  \"name\": \"create_folder\",\n",
            "  \"arguments\": \"{\\\"name\\\": \\\"small-file\\\"}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"big-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: big-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: big-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"small-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: small-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: small-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb4165d50> JSON: {\n",
            "  \"name\": \"get_folder_contents\",\n",
            "  \"arguments\": \"{\\\"path\\\": \\\"/content/sample_data\\\"}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"big-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: big-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: big-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"small-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: small-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: small-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_folder_contents', 'arguments': '{\"path\": \"/content/sample_data\"}'}}, {'role': 'function', 'name': 'get_folder_contents', 'content': '[{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned [{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]. Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb4260c70> JSON: {\n",
            "  \"name\": \"copy_file\",\n",
            "  \"arguments\": \"{\\\"src\\\": \\\"/content/sample_data/mnist_train_small.csv\\\", \\\"dest\\\": \\\"/content/big-file\\\"}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"big-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: big-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: big-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"small-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: small-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: small-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_folder_contents', 'arguments': '{\"path\": \"/content/sample_data\"}'}}, {'role': 'function', 'name': 'get_folder_contents', 'content': '[{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned [{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]. Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'copy_file', 'arguments': '{\"src\": \"/content/sample_data/mnist_train_small.csv\", \"dest\": \"/content/big-file\"}'}}, {'role': 'function', 'name': 'copy_file', 'content': '\"Copy successfull: /content/sample_data/mnist_train_small.csv to /content/big-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Copy successfull: /content/sample_data/mnist_train_small.csv to /content/big-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb42a6480> JSON: {\n",
            "  \"name\": \"copy_file\",\n",
            "  \"arguments\": \"{\\\"src\\\": \\\"/content/sample_data/README.md\\\", \\\"dest\\\": \\\"/content/small-file\\\"}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"big-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: big-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: big-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'create_folder', 'arguments': '{\"name\": \"small-file\"}'}}, {'role': 'function', 'name': 'create_folder', 'content': '\"Folder creation succesfull: small-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Folder creation succesfull: small-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_folder_contents', 'arguments': '{\"path\": \"/content/sample_data\"}'}}, {'role': 'function', 'name': 'get_folder_contents', 'content': '[{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned [{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]. Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'copy_file', 'arguments': '{\"src\": \"/content/sample_data/mnist_train_small.csv\", \"dest\": \"/content/big-file\"}'}}, {'role': 'function', 'name': 'copy_file', 'content': '\"Copy successfull: /content/sample_data/mnist_train_small.csv to /content/big-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Copy successfull: /content/sample_data/mnist_train_small.csv to /content/big-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'copy_file', 'arguments': '{\"src\": \"/content/sample_data/README.md\", \"dest\": \"/content/small-file\"}'}}, {'role': 'function', 'name': 'copy_file', 'content': '\"Copy successfull: /content/sample_data/README.md to /content/small-file\"'}, {'role': 'user', 'content': 'User query was - Create two new folder namely big-file and small-file. Then copy largest file from sample_data folder to big-file and smallest to small-file. The previous function returned \"Copy successfull: /content/sample_data/README.md to /content/small-file\". Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': 'The task has been completed successfully. The largest file from the sample_data folder has been copied to the big-file folder, and the smallest file has been copied to the small-file folder. Is there anything else I can help you with?'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The task has been completed successfully. The largest file from the sample_data folder has been copied to the big-file folder, and the smallest file has been copied to the small-file folder. Is there anything else I can help you with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# modified folder structure\n",
        "\n",
        "!ls -lR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIydyayREcOm",
        "outputId": "41fa2270-89f9-42f2-c238-c5450388a0a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "total 20\n",
            "drwxr-xr-x 2 root root 4096 Jun 26 14:16 big-file\n",
            "drwxr-xr-x 2 root root 4096 Jun 26 14:10 new_folder1\n",
            "drwxr-xr-x 2 root root 4096 Jun 26 14:11 new_folder2\n",
            "drwxr-xr-x 1 root root 4096 Jun 23 01:15 sample_data\n",
            "drwxr-xr-x 2 root root 4096 Jun 26 14:17 small-file\n",
            "\n",
            "./big-file:\n",
            "total 35668\n",
            "-rw-r--r-- 1 root root 36523880 Jun 26 14:16 mnist_train_small.csv\n",
            "\n",
            "./new_folder1:\n",
            "total 0\n",
            "\n",
            "./new_folder2:\n",
            "total 0\n",
            "\n",
            "./sample_data:\n",
            "total 55504\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root   301141 Jun 23 01:15 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root  1706430 Jun 23 01:15 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root 18289443 Jun 23 01:15 mnist_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jun 23 01:15 mnist_train_small.csv\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 README.md\n",
            "\n",
            "./small-file:\n",
            "total 4\n",
            "-rwxr-xr-x 1 root root 930 Jun 26 14:17 README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example - Getting unexpected function_call\n",
        "In this scenario, the initial step went as anticipated, where the API provided the correct function and argument. However, following that, the API unexpectedly responded with a `python` function that includes code to identify the smallest file, which is unnecessary. It's important to note that we did not specify a `python` function anywhere.\n",
        "\n",
        "Related issue - https://community.openai.com/t/function-calling-a-python-function-is-frequently-called-even-though-it-does-not-exist-in-the-functions-parameter/264481"
      ],
      "metadata": {
        "id": "guSyfEz7E9V8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = \"Show me size of smallest file in sample data folder and copy that file to a new folder named test_copy\"\n",
        "answer = ask_openai(user_query)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "yhjz0XpaxOJy",
        "outputId": "24cb6b65-fbb6-4ee4-f9cc-dfe493d1c804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Show me size of smallest file in sample data folder and copy that file to a new folder named test_copy'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb4175ee0> JSON: {\n",
            "  \"name\": \"get_folder_contents\",\n",
            "  \"arguments\": \"{\\n  \\\"path\\\": \\\"/content/sample_data\\\"\\n}\"\n",
            "}}\n",
            "Sleeping: 100%|██████████| 30/30 [00:30<00:00,  1.00s/it]\n",
            "INFO:OpenAI-Example:Calling API: [{'role': 'system', 'content': '\\n                You are intelligent chatbot.\\n                You are only allowed to use specified functions with relevant order by looking at the user query and context.\\n                You don’t have a python function available, never attempt to call python\\n                '}, {'role': 'user', 'content': 'Show me size of smallest file in sample data folder and copy that file to a new folder named test_copy'}, {'role': 'assistant', 'content': None, 'function_call': {'name': 'get_folder_contents', 'arguments': '{\"path\": \"/content/sample_data\"}'}}, {'role': 'function', 'name': 'get_folder_contents', 'content': '[{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]'}, {'role': 'user', 'content': 'User query was - Show me size of smallest file in sample data folder and copy that file to a new folder named test_copy. The previous function returned [{\"file_name\": \"anscombe.json\", \"size\": \"1.7 KB\"}, {\"file_name\": \"README.md\", \"size\": \"930 bytes\"}, {\"file_name\": \"mnist_test.csv\", \"size\": \"18.29 MB\"}, {\"file_name\": \"mnist_train_small.csv\", \"size\": \"36.52 MB\"}, {\"file_name\": \"california_housing_train.csv\", \"size\": \"1.71 MB\"}, {\"file_name\": \"california_housing_test.csv\", \"size\": \"301.14 KB\"}]. Suggest next steps if any as per user query and context, else respond with relevant answer'}]\n",
            "INFO:OpenAI-Example:API Response: {'role': 'assistant', 'content': None, 'function_call': <OpenAIObject at 0x7f1cb40d0860> JSON: {\n",
            "  \"name\": \"python\",\n",
            "  \"arguments\": \"# Extracting the size of the smallest file\\nfile_list = [{\\\"file_name\\\": \\\"anscombe.json\\\", \\\"size\\\": \\\"1.7 KB\\\"}, {\\\"file_name\\\": \\\"README.md\\\", \\\"size\\\": \\\"930 bytes\\\"}, {\\\"file_name\\\": \\\"mnist_test.csv\\\", \\\"size\\\": \\\"18.29 MB\\\"}, {\\\"file_name\\\": \\\"mnist_train_small.csv\\\", \\\"size\\\": \\\"36.52 MB\\\"}, {\\\"file_name\\\": \\\"california_housing_train.csv\\\", \\\"size\\\": \\\"1.71 MB\\\"}, {\\\"file_name\\\": \\\"california_housing_test.csv\\\", \\\"size\\\": \\\"301.14 KB\\\"}]\\n\\n# Sorting the file list based on size\\nsorted_files = sorted(file_list, key=lambda x: x['size'])\\n\\n# Extracting the smallest file size\\nsmallest_size = sorted_files[0]['size']\\n\\nsmallest_size\"\n",
            "}}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-153-d34fb97eb919>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0muser_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Show me size of smallest file in sample data folder and copy that file to a new folder named test_copy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-ae6c5ddfa7a5>\u001b[0m in \u001b[0;36mask_openai\u001b[0;34m(user_query, openai_model)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mfunc_call_resp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'function_call'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0midentified_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_call_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0midentified_func_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_call_resp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arguments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mfunc_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midentified_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0midentified_func_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             messages.extend([\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBzGN4h3JL8C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}